{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dc9285a",
   "metadata": {},
   "source": [
    "#  Leftover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ebf4e1",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "- Evaluation metric: **F1 Scores**\n",
    "- TF-IDF Vectorizer\n",
    "    - kein lowercase\n",
    "    - stop words werden entfernt\n",
    "    - keine max features\n",
    "- Top $n$ classes = most frequent classes\n",
    "- CLEAN HTML auch f√ºr Test Set (ansonsten unglaublich schlechte Accuracy und etwas sinnlos)\n",
    "\n",
    "\n",
    "#### Label: `group_representatives`\n",
    "\n",
    "| Experiment | KNN F1 (Precision) | LSVM F1 (Precision) |\n",
    "| ---------- |:-----:| ----:|\n",
    "| Plain Text (all samples) | **0.4295** (0.4774) | **0.6874** (0.7178) |\n",
    "| Plain HTML (all samples) | **0.1474** (0.1954) | **0.5109** (0.6139) |\n",
    "| | | |\n",
    "| Plain Text ([DE] all samples) | **0.5224** (0.5563) | **0.7209** (0.7476) |\n",
    "| Plain HTML ([DE] all samples) | **0.1515** (0.1915) | **0.5194** (0.6232) |\n",
    "| Plain Text ([DE, EN] all samples) | **0.472** (0.5258) | **0.7012** (0.7262) |\n",
    "| Plain HTML ([DE, EN] all samples) | **0.1466** (0.197) | **0.5166** (0.6211) |\n",
    "| | | |\n",
    "| Plain Text (all samples) (Top 10 classes) | **0.2059** (0.203) | **0.3024** (0.2721) |\n",
    "| Plain HTML (all samples) (Top 10 classes) | **0.0943** (0.0995) | **0.2376** (0.2323) |\n",
    "| Plain Text ([DE] all samples) (Top 10 classes) | **0.2212** (0.2036) | **0.3006** (0.2687) |\n",
    "| Plain HTML ([DE] all samples) (Top 10 classes) | **0.089** (0.0912) | **0.2231** (0.2164) |\n",
    "| | | |\n",
    "| Clean HTML (all samples)  | **0.0612** (0.0912) | **0.5086** (0.6424) |\n",
    "| Clean HTML ([DE] all samples)  | **0.0624** (0.0806) | **0.5579** (0.6607) |\n",
    "| Clean HTML ([DE, EN] all samples)  | **0.065** (0.088) | **0.5354** (0.645) |\n",
    "\n",
    "#### Label: `industry`\n",
    "\n",
    "| Experiment | KNN F1 (Precision) | LSVM F1 (Precision) |\n",
    "| ---------- |:-----:| ----:|\n",
    "| Plain Text (all samples)  | **0.3788** (0.4416) | **0.6218** (0.6423) |\n",
    "| Plain HTML (all samples)  | **0.1295** (0.1933) | **0.4589** (0.537) |\n",
    "| | | |\n",
    "| Plain Text ([DE] all samples)  | **0.4592** (0.5016) | **0.6446** (0.6591) |\n",
    "| Plain HTML ([DE] all samples)  | **0.1285** (0.1949) | **0.4574** (0.5382) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9cbb1f",
   "metadata": {},
   "source": [
    "## Some informations about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e2f2b74",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent countries:\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8153326865cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Most frequent countries:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Most frequent countries:\\n\")\n",
    "train.country.value_counts().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d588b0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_percentage = train.apply(lambda row: len(row.text)/len(row.html), axis=1)\n",
    "\n",
    "print(f\"Average/mean share of actual/plain text of HTML: {np.round(np.mean(text_percentage), decimals=2)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222edc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes = list(np.unique(train[CLASS_NAMES]))\n",
    "\n",
    "print(f\"{CLASS_NAMES} ({len(unique_classes)}): \\n\")\n",
    "for idx, i in enumerate(unique_classes):\n",
    "    print(str(idx+1)+\". \"+str(i), end=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c097b2",
   "metadata": {},
   "source": [
    "## SUBSAMPLING\n",
    "\n",
    "- Only specific language (e.g. \"DE\")\n",
    "- Only $n$ samples (e.g. 1000)\n",
    "- Stratified sampling by industry col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51c8eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SUBSAMPLING:\n",
    "    if USED_LANG[0] != \"ALL\":\n",
    "        train = train[train.country.isin(USED_LANG)]\n",
    "    if N_SAMPLES < train.shape[0]:\n",
    "        max_samples = N_SAMPLES\n",
    "    else:\n",
    "        max_samples = train.shape[0]\n",
    "    train = train.sample(n=max_samples, weights=CLASS_COL, random_state=1).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "unique_sampled_classes = len(train[CLASS_COL].unique())\n",
    "print(\"Count of classes (sampled train):\", unique_sampled_classes)\n",
    "print(\"Equal to original train?\", unique_sampled_classes == len(unique_classes))\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee55902",
   "metadata": {},
   "source": [
    "## USE TOP N LABELS\n",
    "\n",
    "- only use top n classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e0a57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_TOP_LABELS:\n",
    "    top_n_classes = train[CLASS_COL].value_counts()[:TOP_N_LABELS].keys()\n",
    "    train = train[train[CLASS_COL].isin(top_n_classes)]\n",
    "    \n",
    "    unique_classes = list(np.unique(train[CLASS_NAMES]))\n",
    "\n",
    "    print(f\"{CLASS_NAMES} ({len(unique_classes)}): \\n\")\n",
    "    for idx, i in enumerate(unique_classes):\n",
    "        print(str(idx+1)+\". \"+str(i), end=\"\\t\")\n",
    "else:\n",
    "    print(\"Using all labels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6992b2ed",
   "metadata": {},
   "source": [
    "# Data preprocessing (vectorizing, dimension reducing etc.)\n",
    "\n",
    "- ignore terms with a document frequency > MAX_DOCUMENT_FREQUENCY (`max_df` in TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2e2091",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_labels = train[CLASS_COL].values\n",
    "unique_train_labels = list(np.unique(train[CLASS_COL]))\n",
    "print(\"Count of unique classes in train set:\", len(unique_train_labels))\n",
    "print(\"Count of unique languages in train set:\", len(np.unique(train[\"country\"].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dfcf94",
   "metadata": {},
   "source": [
    "### Remove tokens with POS-Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca01386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if POS_TAGGING:\n",
    "    train_text = remove_pos(train, pos_tags=POS_TAGS)\n",
    "else:\n",
    "    train_text = train[TEXT_COL]\n",
    "    print(\"No POS TAGS are removed.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a96304",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test = pd.read_csv(TEST_PATH_CSV)\n",
    "\n",
    "if SUBSAMPLING:\n",
    "    if USED_LANG[0] != \"ALL\":\n",
    "        test = test[test.country.isin(USED_LANG)]\n",
    "    test = test.sample(n=test.shape[0], weights=CLASS_COL, random_state=1).reset_index(drop=True)\n",
    "    \n",
    "\n",
    "test_vector = vectorizer.transform(test[TEXT_COL].values)\n",
    "test_labels = test[CLASS_COL].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed00794a",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6979ad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"K-Nearest Neighbors CLF\", \"\\n-------------------------\")\n",
    "# training\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(train_vector, train_labels)\n",
    "\n",
    "# prediction\n",
    "train_preds = clf.predict(test_vector)\n",
    "\n",
    "# evaluation\n",
    "precision = precision_score(test_labels, train_preds, average=\"macro\", zero_division=0)\n",
    "recall = recall_score(test_labels, train_preds, average=\"macro\", zero_division=0)\n",
    "f1 = f1_score(test_labels, train_preds, average=\"macro\", zero_division=0)\n",
    "clf1_f1 = np.round(f1, decimals=4)\n",
    "clf1_precision = np.round(precision, decimals=4)\n",
    "\n",
    "print(np.round(precision, decimals=4), \"\\tPrecision\")\n",
    "print(np.round(recall, decimals=4), \"\\tRecall\")\n",
    "print(np.round(f1, decimals=4), \"\\tF1\")\n",
    "print()\n",
    "\n",
    "clf_report = classification_report(test_labels, \n",
    "                                   train_preds, \n",
    "                                   target_names = np.unique(test[CLASS_NAMES]), \n",
    "                                   zero_division = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159eccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = \"| \"\n",
    "\n",
    "if TEXT_COL == \"text\":\n",
    "    result += \"Plain Text\"\n",
    "else:\n",
    "    result += \"HTML\"\n",
    "    \n",
    "result += \" (\"\n",
    "    \n",
    "if SUBSAMPLING:\n",
    "    result += \"[\" + \", \".join(USED_LANG) + \"]\"\n",
    "    if N_SAMPLES < train.shape[0]:\n",
    "        result += f\" {N_SAMPLES} samples\"\n",
    "    else:\n",
    "        result += \" all samples\"\n",
    "else:\n",
    "    result += \"all samples\"\n",
    "    \n",
    "result += \") \"\n",
    "\n",
    "if USE_TOP_LABELS:\n",
    "    result += f\"(Top {TOP_N_LABELS} classes)\"\n",
    "        \n",
    "result += f\" | **{clf1_f1}** ({clf1_precision}) | **{clf2_f1}** ({clf2_precision}) |\"\n",
    "print(CLASS_COL)\n",
    "print()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c5d2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139f5132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
