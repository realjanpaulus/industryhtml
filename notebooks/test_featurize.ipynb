{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56775f5c",
   "metadata": {},
   "source": [
    "# Test featurize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "560b2b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn classification\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# sklearn general\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             confusion_matrix, \n",
    "                             classification_report, \n",
    "                             f1_score, \n",
    "                             precision_score,\n",
    "                             recall_score)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "import ujson as json\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from app.utils import (clean_boilerplate, \n",
    "                       clean_string,\n",
    "                       clean_website, \n",
    "                       detect_XML, \n",
    "                       extract_meta_informations,\n",
    "                       reduce_whitespace,\n",
    "                       remove_special_characters,\n",
    "                       remove_tags, \n",
    "                       tokenizing_html, \n",
    "                       trim_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "a24b0a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.47 s, sys: 234 ms, total: 2.7 s\n",
      "Wall time: 2.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>industry</th>\n",
       "      <th>industry_label</th>\n",
       "      <th>group</th>\n",
       "      <th>group_representative</th>\n",
       "      <th>html</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>country</th>\n",
       "      <th>group_representative_label</th>\n",
       "      <th>meta</th>\n",
       "      <th>chtml</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://12-18.com</td>\n",
       "      <td>31</td>\n",
       "      <td>Hospitality</td>\n",
       "      <td>rec, serv, tran</td>\n",
       "      <td>30</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"de\"&gt;\\n&lt;head&gt;\\n\\t&lt;...</td>\n",
       "      <td>12.18. Investment Management - ANDERS. AUS PRI...</td>\n",
       "      <td>xing</td>\n",
       "      <td>DE</td>\n",
       "      <td>Leisure, Travel &amp; Tourism</td>\n",
       "      <td>Ein glückliches Investment ist das Resultat ha...</td>\n",
       "      <td>&lt;html&gt;\\n&lt;head&gt;\\n\\t&lt;title&gt;12.18. Investment Man...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                url  industry industry_label            group  \\\n",
       "0  http://12-18.com        31    Hospitality  rec, serv, tran   \n",
       "\n",
       "   group_representative                                               html  \\\n",
       "0                    30  <!DOCTYPE html>\\n<html lang=\"de\">\\n<head>\\n\\t<...   \n",
       "\n",
       "                                                text source country  \\\n",
       "0  12.18. Investment Management - ANDERS. AUS PRI...   xing      DE   \n",
       "\n",
       "  group_representative_label  \\\n",
       "0  Leisure, Travel & Tourism   \n",
       "\n",
       "                                                meta  \\\n",
       "0  Ein glückliches Investment ist das Resultat ha...   \n",
       "\n",
       "                                               chtml  \n",
       "0  <html>\\n<head>\\n\\t<title>12.18. Investment Man...  "
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(\"../data/ctrain.csv\", nrows=1000).fillna(\"\")\n",
    "train = train.fillna(\"\")\n",
    "test = pd.read_csv(\"../data/ctest.csv\", nrows=200).fillna(\"\")\n",
    "test = test.fillna(\"\")\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "a4c684a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_mtx(data, vectorizer=None, vectorizer2=None):\n",
    "    \"\"\" \"\"\"\n",
    "    mtx = []\n",
    "    plain_text = data.text\n",
    "    meta_text = data.meta\n",
    "    \n",
    "    # TF-IDF counts as features\n",
    "    if vectorizer:\n",
    "        plain_vector = vectorizer.transform(plain_text)#.toarray().tolist()\n",
    "        meta_vector = vectorizer2.transform(meta_text)#.toarray().tolist()\n",
    "        plain_vectorizer, meta_vectorizer = _, _\n",
    "        \n",
    "    else:\n",
    "        plain_vectorizer = TfidfVectorizer()\n",
    "        meta_vectorizer = TfidfVectorizer()\n",
    "        \n",
    "        plain_vector = plain_vectorizer.fit_transform(plain_text)#.toarray().tolist()\n",
    "        meta_vector = meta_vectorizer.fit_transform(meta_text)#.toarray().tolist()\n",
    "        \n",
    "    #mtx.extend(plain_vector)\n",
    "    #return np.array(mtx), plain_vectorizer, meta_vectorizer\n",
    "    #print(plain_vector)\n",
    "    #mtx.extend(meta_vector)\n",
    "    #mtx.extend([0.66666])\n",
    "    #mtx.append(plain_vector)\n",
    "    #mtx = list(map(list, zip(*mtx)))\n",
    "    #return np.array(mtx), plain_vectorizer, meta_vectorizer\n",
    "    \n",
    "    print(plain_vector.toarray())\n",
    "    print(plain_vector.shape)\n",
    "    \n",
    "    \n",
    "    mtx = sp.hstack([plain_vector, meta_vector])\n",
    "    return mtx, plain_vectorizer, meta_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "cfd235fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4]])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [1, 2, 3, 4]\n",
    "np.reshape(l, (4, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "01cec4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 16631)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "17535093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15565, 15565)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0]), len(X_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "4d1eba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse as sp\n",
    "\n",
    "counts = CountVectorizer().fit_transform(train['text'].values)\n",
    "ones = np.ones(shape=(len(train), 1))\n",
    "X = sp.hstack([counts, ones])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "99b39799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse as sp\n",
    "\n",
    "counts = CountVectorizer().fit_transform(train['text'].values)\n",
    "count2 = CountVectorizer().fit_transform(train['meta'].values)\n",
    "X = sp.hstack([counts, count2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "ab1dacf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10x3448 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4768 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "5a0f6130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "be9e3efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 3., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 1., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ffdc4c",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "d1bf9700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02203047 0.01468698 0.00734349 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.04021404 0.02010702 0.02010702]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "(3, 1489)\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n",
      "(1, 1489)\n"
     ]
    }
   ],
   "source": [
    "X_train, vectorizer, vectorizer2 = get_feature_mtx(train)\n",
    "y_train = train.group_representative_label\n",
    "X_test, _, _ = get_feature_mtx(test, vectorizer=vectorizer, vectorizer2=vectorizer2)\n",
    "y_test = test.group_representative_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "ac387513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DE'"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0].country"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7908b227",
   "metadata": {},
   "source": [
    "http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "f33f07e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "import pandas as pd\n",
    "\n",
    "class CountryTransformer(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        countries = pd.DataFrame(X['country'].apply(lambda x: len(x)))\n",
    "        return countries\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "5eb6e284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country\n",
       "0        2\n",
       "1        2\n",
       "2        2"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CountryTransformer().transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "7e4fb50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "\n",
    "def get_text_length(x):\n",
    "    return np.array([len(t) for t in x]).reshape(-1, 1)\n",
    "\n",
    "class DataFrameColumnExtracter(TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.column]\n",
    "\n",
    "    \n",
    "plain_text = Pipeline([\n",
    "            (\"extract_plain_text\", DataFrameColumnExtracter(\"text\")),\n",
    "            (\"plain_text_vect\", TfidfVectorizer()),\n",
    "        ])\n",
    "meta_text = Pipeline([\n",
    "            (\"extract_meta_text\", DataFrameColumnExtracter(\"meta\")),\n",
    "            (\"meta_text_vect\", TfidfVectorizer()),\n",
    "        ])\n",
    "    \n",
    "pipe = Pipeline([\n",
    "    (\"features\", FeatureUnion([\n",
    "        (\"plain_text\", plain_text),\n",
    "        (\"meta_text\", meta_text),\n",
    "    ])),\n",
    "    (\"xgb_linear\", XGBClassifier(booster=\"gblinear\")),\n",
    "    #(\"svm\", LinearSVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "e280babc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train, train.group_representative_label\n",
    "X_test, y_test = test, test.group_representative_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "686c302c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpaulus/miniconda3/envs/industry/lib/python3.9/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:56:52] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CPU times: user 9.93 s, sys: 43.2 ms, total: 9.97 s\n",
      "Wall time: 3.53 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.255"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipe.fit(X_train, y_train)\n",
    "pred = pipe.predict(X_test)\n",
    "score = accuracy_score(pred, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e300780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c132113c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7b3a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "caa5061e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpaulus/miniconda3/envs/industry/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/jpaulus/miniconda3/envs/industry/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "X_train = np.array([\"new york is a hell of a town\",\n",
    "                    \"new york was originally dutch\",\n",
    "                    \"new york is also called the big apple\",\n",
    "                    \"nyc is nice\",\n",
    "                    \"the capital of great britain is london. london is a huge metropolis which has a great many number of people living in it. london is also a very old town with a rich and vibrant cultural history.\",\n",
    "                    \"london is in the uk. they speak english there. london is a sprawling big city where it's super easy to get lost and i've got lost many times.\",\n",
    "                    \"london is in england, which is a part of great britain. some cool things to check out in london are the museum and buckingham palace.\",\n",
    "                    \"london is in great britain. it rains a lot in britain and london's fogs are a constant theme in books based in london, such as sherlock holmes. the weather is really bad there.\",])\n",
    "y_train = np.array([[0],[0],[0],[0],[1],[1],[1],[1]])\n",
    "\n",
    "X_test = np.array([\"it's a nice day in nyc\",\n",
    "                   'i loved the time i spent in london, the weather was great, though there was a nip in the air and i had to wear a jacket.'\n",
    "                   ])   \n",
    "target_names = ['Class 1', 'Class 2']\n",
    "\n",
    "\n",
    "def get_text_length(x):\n",
    "    return np.array([len(t) for t in x]).reshape(-1, 1)\n",
    "\n",
    "classifier = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('text', Pipeline([\n",
    "            ('vectorizer', CountVectorizer(min_df=1,max_df=2)),\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "        ])),\n",
    "        ('length', Pipeline([\n",
    "            ('count', FunctionTransformer(get_text_length, validate=False)),\n",
    "        ]))\n",
    "    ])),\n",
    "    ('clf', LinearSVC())])\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "predicted = classifier.predict(X_test)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67472274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b7ba54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "320671e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TextColumn</th>\n",
       "      <th>NumericColumn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sample Text1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sample Text2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     TextColumn  NumericColumn\n",
       "0  Sample Text1              2\n",
       "1  Sample Text2              1"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.DataFrame({'TextColumn':['Sample Text1','Sample Text2'], \n",
    "                        'NumericColumn': [2,1]})\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "dcfd6f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from scipy import sparse\n",
    "\n",
    "tv = TfidfVectorizer(min_df = 0.05, max_df = 0.5)\n",
    "X = tv.fit_transform(dataset['TextColumn'])\n",
    "vocab = tv.get_feature_names()\n",
    "\n",
    "X1 = pd.DataFrame(X.toarray(), columns = vocab)\n",
    "X1['NumericColumn'] = dataset['NumericColumn']\n",
    "\n",
    "\n",
    "X_sparse = sparse.csr_matrix(X1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "d890a8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_sparse.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feafe884",
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearSVC().fit(X_sparse, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
