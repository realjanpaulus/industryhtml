{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Industries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODOS \n",
    "\n",
    "- \"country\" als column\n",
    "- preprocessing function einführen\n",
    "    - `\\n` weg\n",
    "    - andere unnütze Zeichen wie `|` etc.\n",
    "- remove pos einführen (siehe `clustering_whole_corpus`)\n",
    "    - vielleicht mit Language identifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDEEN\n",
    "\n",
    "### Datensatzaufbereitung\n",
    "\n",
    "- Übersetzung der Websites in einheitliche Sprache (z.b. Englisch)\n",
    "- Andere Klassenlabels?\n",
    "    - Erst allgemeinere Klassen und dann in diesen Klassen feiner klassifizieren?\n",
    "        - Von: https://towardsdatascience.com/industrial-classification-of-websites-by-machine-learning-with-hands-on-python-3761b1b530f1\n",
    "            - Technology, Office, & Education products website (Class_1)\n",
    "            - Consumer products website (Class_2)\n",
    "            - Industrial Tools and Hardware products website (Class_3)\n",
    "    - seltene Klassenlables wegwerfen?\n",
    "\n",
    "### HTML Klassifizierung\n",
    "\n",
    "\n",
    "- Text zusammenfassen und dann klassifizieren? Dafür auch HTML-Tags verwenden?\n",
    "\n",
    "- HTML Struktur verwenden, um vorher **Boilerplate Content** von Main Content zu entfernen:\n",
    "    - Plain Text ist sehr noisy (viel unnötiges drin)\n",
    "- Bestimmten Wörtern/Tags höhere Gewichtungen geben\n",
    "    - Anchor Text (= klickbarer Text in einem Hyperlink)\n",
    "        - alleine zu wenig Inhalt (QI, S. 12)\n",
    "        - umliegende Wörter interessant! (QI, S. 12)\n",
    "        - auch für Nachbar-Seiten-Ansatz\n",
    "    - Title, Headers (QI, S. 12)\n",
    "        - auch für Nachbar-Seiten-Ansatz\n",
    "    - Keywords für Branchen\n",
    "        ```python3  \n",
    "        Class_1_keywords = ['Office', 'School', 'phone', 'Technology', 'Electronics', 'Cell', 'Business', 'Education', 'Classroom']\n",
    "        \n",
    "        Class_2_keywords = ['Restaurant', 'Hospitality', 'Tub', 'Drain', 'Pool', 'Filtration', 'Floor', 'Restroom', 'Consumer', 'Care', 'Bags', 'Disposables']\n",
    "        \n",
    "        Class_3_keywords = ['Pull', 'Lifts', 'Pneumatic', 'Emergency', 'Finishing', 'Hydraulic', 'Lockout', 'Towers', 'Drywall', 'Tools', 'Packaging', 'Measure', 'Tag ']\n",
    "        ```\n",
    "- flat classification oder hierarchical classification?\n",
    "    - flat: parallele Klassen\n",
    "    - hierarchical: hierarchische Klassen, bauen aufeinander auf\n",
    "- Nur nach bestimmten Keywords filtern? (das geht jedoch mehr Richtung PLAIN-Textclassification)\n",
    "- \"implicit links\": Seiten, die beide bei Suche von **Suchmaschine** erschienen sind und auf die beide der User geklickt hat (QI, S. 12) &rarr; nicht wirklich realisierbar\n",
    "\n",
    "\n",
    "## Paper / Repos\n",
    "\n",
    "- **Boilerplate Removal using a Neural Sequence Labeling Model** (2020): https://arxiv.org/pdf/2004.14294.pdf\n",
    "    - Verbesserung von **Web2Text** &rarr; basiert nicht auf teuren, handgemachten Feature Engineering\n",
    "    - <u>Hypothese</u>: \"Our hypothesis is that the **order** of text blocks in a web page **encodes important information** about their type, i.e. content or boilerplate, as the placement is determined by the authoring style\"\n",
    "- **Web2Text: Deep Structured Boilerplate Removal** (2018): https://arxiv.org/pdf/1801.02607.pdf\n",
    "- **Mozillas readability**: https://github.com/mozilla/readability\n",
    "- **Webpage Classification based on Compound of Using HTML Features & URLFeatures and Features of Sibling Pages** (2010): https://www.researchgate.net/publication/220419545_Webpage_Classification_based_on_Compound_of_Using_HTML_Features_URL_Features_and_Features_of_Sibling_Pages\n",
    "    - TODO\n",
    "- **Web Page Classification: Features and Algorithms** (2009): https://www.cs.ucf.edu/~dcm/Teaching/COT4810-Fall%202012/Literature/WebPageClassification.pdf\n",
    "    - S. 7: Using On-Page Features\n",
    "        - GOLUB, ARDO (2005): title, headings, metadata, main text\n",
    "    - TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "Evaluation metric: **F1 Scores**\n",
    "\n",
    "| Experiment | Dummy | LSVM |\n",
    "| ---------- |:-----:| ----:|\n",
    "| Plain Text (DE, 10000 samples) | 0.0268 | 0.6326 |\n",
    "| Plain Text (DE, all samples) | 0.0271 | 0.6501 |\n",
    "| Plain HTML (DE, 10000 samples) | 0.0319 | 0.5648 |\n",
    "|  |  |  |\n",
    "|  |  |  |\n",
    "|  |  |  |\n",
    "|  |  |  |\n",
    "|  |  |  |\n",
    "|  |  |  |\n",
    "|  |  |  |\n",
    "|  |  |  |\n",
    "|  |  |  |\n",
    "|  |  |  |\n",
    "|  |  |  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn classification\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# sklearn clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# sklearn general\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "import ujson as json\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from app.utils import remove_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_PATH = \"../data/\"\n",
    "TRAIN_PATH_CSV = DATA_DIR_PATH + \"train.csv\"\n",
    "TEST_PATH_CSV = DATA_DIR_PATH + \"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"text\" or \"html\"\n",
    "TEXT_COL = \"text\"\n",
    "\n",
    "# \"group_representative\", \"industry\", \"industry_label\" or \"group\"\n",
    "CLASS_COL = \"group_representative\"\n",
    "TEXT_CLASS_COL = \n",
    "\n",
    "DIM_RED = False\n",
    "MAX_DOCUMENT_FREQUENCY = 1.\n",
    "MAX_FEATURES = 1000000\n",
    "LOWERCASE = False\n",
    "STOP_WORDS = get_stop_words(\"de\")\n",
    "\n",
    "# POS TAGGING\n",
    "POS_TAGGING = False\n",
    "POS_TAGS = [\"NOUN\"]\n",
    "\n",
    "# SUBSAMPLING\n",
    "SUBSAMPLING = True\n",
    "N_SAMPLES = 10000\n",
    "USED_LANG = [\"DE\"] # \"ALL\" for no removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load train csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.4 s, sys: 2.09 s, total: 21.5 s\n",
      "Wall time: 21.5 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>industry</th>\n",
       "      <th>industry_label</th>\n",
       "      <th>group</th>\n",
       "      <th>group_representative</th>\n",
       "      <th>html</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.dps-software.de</td>\n",
       "      <td>4</td>\n",
       "      <td>Computer Software</td>\n",
       "      <td>tech</td>\n",
       "      <td>96</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"de\"&gt;\\n&lt;head&gt;\\n\\n&lt;...</td>\n",
       "      <td>DPS Software: DPS Software GmbH - Wir finden L...</td>\n",
       "      <td>xing</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.sales-rockstars.com</td>\n",
       "      <td>96</td>\n",
       "      <td>Information Technology and Services</td>\n",
       "      <td>tech</td>\n",
       "      <td>96</td>\n",
       "      <td>&lt;!doctype html&gt;\\n&lt;html lang=\"de-DE\"&gt;\\n  &lt;head&gt;...</td>\n",
       "      <td>Sales Rockstars – Kommunikationsagentur für de...</td>\n",
       "      <td>xing</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.immobilien-ps.de</td>\n",
       "      <td>44</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>cons, fin, good</td>\n",
       "      <td>44</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"de-DE\" class=\"no-...</td>\n",
       "      <td>Paul Schmidmaier Immobilien – Immobilienmakler...</td>\n",
       "      <td>xing</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.hdp-profitools.de</td>\n",
       "      <td>133</td>\n",
       "      <td>Wholesale</td>\n",
       "      <td>good</td>\n",
       "      <td>133</td>\n",
       "      <td>&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 S...</td>\n",
       "      <td>HDP Bauwerkzeuge - Ihr leistungsstarker Servic...</td>\n",
       "      <td>xing</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.avaya.com</td>\n",
       "      <td>8</td>\n",
       "      <td>Telecommunications</td>\n",
       "      <td>gov, tech</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;!doctype html&gt; \\r\\n\\t&lt;html class=\"no-js\" lang...</td>\n",
       "      <td>Avaya | Leader in Business Communication and C...</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              url  industry  \\\n",
       "0      http://www.dps-software.de         4   \n",
       "1  http://www.sales-rockstars.com        96   \n",
       "2     http://www.immobilien-ps.de        44   \n",
       "3    http://www.hdp-profitools.de       133   \n",
       "4            http://www.avaya.com         8   \n",
       "\n",
       "                        industry_label            group  group_representative  \\\n",
       "0                    Computer Software             tech                    96   \n",
       "1  Information Technology and Services             tech                    96   \n",
       "2                          Real Estate  cons, fin, good                    44   \n",
       "3                            Wholesale             good                   133   \n",
       "4                   Telecommunications        gov, tech                     8   \n",
       "\n",
       "                                                html  \\\n",
       "0  <!DOCTYPE html>\\n<html lang=\"de\">\\n<head>\\n\\n<...   \n",
       "1  <!doctype html>\\n<html lang=\"de-DE\">\\n  <head>...   \n",
       "2  <!DOCTYPE html>\\n<html lang=\"de-DE\" class=\"no-...   \n",
       "3  <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 S...   \n",
       "4  <!doctype html> \\r\\n\\t<html class=\"no-js\" lang...   \n",
       "\n",
       "                                                text    source country  \n",
       "0  DPS Software: DPS Software GmbH - Wir finden L...      xing      DE  \n",
       "1  Sales Rockstars – Kommunikationsagentur für de...      xing      DE  \n",
       "2  Paul Schmidmaier Immobilien – Immobilienmakler...      xing      DE  \n",
       "3  HDP Bauwerkzeuge - Ihr leistungsstarker Servic...      xing      DE  \n",
       "4  Avaya | Leader in Business Communication and C...  linkedin      EN  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(TRAIN_PATH_CSV)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes.iloc[63].industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"group_representative_label\"] = train.apply(lambda row: codes.iloc[row.group_representative].industry_label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>industry</th>\n",
       "      <th>industry_label</th>\n",
       "      <th>group</th>\n",
       "      <th>group_representative</th>\n",
       "      <th>html</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>country</th>\n",
       "      <th>group_representative_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.dps-software.de</td>\n",
       "      <td>4</td>\n",
       "      <td>Computer Software</td>\n",
       "      <td>tech</td>\n",
       "      <td>96</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"de\"&gt;\\n&lt;head&gt;\\n\\n&lt;...</td>\n",
       "      <td>DPS Software: DPS Software GmbH - Wir finden L...</td>\n",
       "      <td>xing</td>\n",
       "      <td>DE</td>\n",
       "      <td>Law Practice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.sales-rockstars.com</td>\n",
       "      <td>96</td>\n",
       "      <td>Information Technology and Services</td>\n",
       "      <td>tech</td>\n",
       "      <td>96</td>\n",
       "      <td>&lt;!doctype html&gt;\\n&lt;html lang=\"de-DE\"&gt;\\n  &lt;head&gt;...</td>\n",
       "      <td>Sales Rockstars – Kommunikationsagentur für de...</td>\n",
       "      <td>xing</td>\n",
       "      <td>DE</td>\n",
       "      <td>Law Practice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.immobilien-ps.de</td>\n",
       "      <td>44</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>cons, fin, good</td>\n",
       "      <td>44</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"de-DE\" class=\"no-...</td>\n",
       "      <td>Paul Schmidmaier Immobilien – Immobilienmakler...</td>\n",
       "      <td>xing</td>\n",
       "      <td>DE</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.hdp-profitools.de</td>\n",
       "      <td>133</td>\n",
       "      <td>Wholesale</td>\n",
       "      <td>good</td>\n",
       "      <td>133</td>\n",
       "      <td>&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 S...</td>\n",
       "      <td>HDP Bauwerkzeuge - Ihr leistungsstarker Servic...</td>\n",
       "      <td>xing</td>\n",
       "      <td>DE</td>\n",
       "      <td>Hospitality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.avaya.com</td>\n",
       "      <td>8</td>\n",
       "      <td>Telecommunications</td>\n",
       "      <td>gov, tech</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;!doctype html&gt; \\r\\n\\t&lt;html class=\"no-js\" lang...</td>\n",
       "      <td>Avaya | Leader in Business Communication and C...</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>EN</td>\n",
       "      <td>Museums and Institutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30287</th>\n",
       "      <td>http://www.connex-stb.de</td>\n",
       "      <td>10</td>\n",
       "      <td>Legal Services</td>\n",
       "      <td>leg</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;!--[if lt IE 7 ]&gt;&lt;html lang=...</td>\n",
       "      <td>Connex: Steuerberatung, Unternehmensberatung, ...</td>\n",
       "      <td>xing</td>\n",
       "      <td>DE</td>\n",
       "      <td>Writing and Editing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30288</th>\n",
       "      <td>http://www.frettwork.de</td>\n",
       "      <td>11</td>\n",
       "      <td>Management Consulting</td>\n",
       "      <td>corp, consulting</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\r\\n&lt;html xmlns=\"https://www.w3...</td>\n",
       "      <td>Frettwork Network\\n\\nDE | EN | NL\\n\\n\\nFRETTWO...</td>\n",
       "      <td>xing</td>\n",
       "      <td>DE</td>\n",
       "      <td>Motion Pictures and Film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30289</th>\n",
       "      <td>http://www.zwf.de</td>\n",
       "      <td>4</td>\n",
       "      <td>Computer Software</td>\n",
       "      <td>tech</td>\n",
       "      <td>96</td>\n",
       "      <td>&lt;!DOCTYPE html&gt; \\n&lt;html dir=\"ltr\" lang=\"de-DE\"...</td>\n",
       "      <td>ERP, Infor, Comet PA\\n\\nZWF Software &amp; Consult...</td>\n",
       "      <td>xing</td>\n",
       "      <td>DE</td>\n",
       "      <td>Law Practice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30290</th>\n",
       "      <td>http://www.imsengineering.co.za</td>\n",
       "      <td>56</td>\n",
       "      <td>Mining &amp; Metals</td>\n",
       "      <td>man</td>\n",
       "      <td>55</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;\\n\\n&lt;...</td>\n",
       "      <td>IMS ENGINEERING - Homepage\\n\\nMENU\\n\\n\\nAbout ...</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>EN</td>\n",
       "      <td>Apparel &amp; Fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30291</th>\n",
       "      <td>http://www.probrand.co.uk</td>\n",
       "      <td>96</td>\n",
       "      <td>Information Technology and Services</td>\n",
       "      <td>tech</td>\n",
       "      <td>96</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\r\\n&lt;html  lang=\"en-GB\"&gt;\\r\\n&lt;he...</td>\n",
       "      <td>Managed IT Support &amp; Services | Browse Our Mar...</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>EN</td>\n",
       "      <td>Law Practice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30292 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   url  industry  \\\n",
       "0           http://www.dps-software.de         4   \n",
       "1       http://www.sales-rockstars.com        96   \n",
       "2          http://www.immobilien-ps.de        44   \n",
       "3         http://www.hdp-profitools.de       133   \n",
       "4                 http://www.avaya.com         8   \n",
       "...                                ...       ...   \n",
       "30287         http://www.connex-stb.de        10   \n",
       "30288          http://www.frettwork.de        11   \n",
       "30289                http://www.zwf.de         4   \n",
       "30290  http://www.imsengineering.co.za        56   \n",
       "30291        http://www.probrand.co.uk        96   \n",
       "\n",
       "                            industry_label             group  \\\n",
       "0                        Computer Software              tech   \n",
       "1      Information Technology and Services              tech   \n",
       "2                              Real Estate   cons, fin, good   \n",
       "3                                Wholesale              good   \n",
       "4                       Telecommunications         gov, tech   \n",
       "...                                    ...               ...   \n",
       "30287                       Legal Services               leg   \n",
       "30288                Management Consulting  corp, consulting   \n",
       "30289                    Computer Software              tech   \n",
       "30290                      Mining & Metals               man   \n",
       "30291  Information Technology and Services              tech   \n",
       "\n",
       "       group_representative  \\\n",
       "0                        96   \n",
       "1                        96   \n",
       "2                        44   \n",
       "3                       133   \n",
       "4                         8   \n",
       "...                     ...   \n",
       "30287                    10   \n",
       "30288                    11   \n",
       "30289                    96   \n",
       "30290                    55   \n",
       "30291                    96   \n",
       "\n",
       "                                                    html  \\\n",
       "0      <!DOCTYPE html>\\n<html lang=\"de\">\\n<head>\\n\\n<...   \n",
       "1      <!doctype html>\\n<html lang=\"de-DE\">\\n  <head>...   \n",
       "2      <!DOCTYPE html>\\n<html lang=\"de-DE\" class=\"no-...   \n",
       "3      <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 S...   \n",
       "4      <!doctype html> \\r\\n\\t<html class=\"no-js\" lang...   \n",
       "...                                                  ...   \n",
       "30287  <!DOCTYPE html>\\n<!--[if lt IE 7 ]><html lang=...   \n",
       "30288  <!DOCTYPE html>\\r\\n<html xmlns=\"https://www.w3...   \n",
       "30289  <!DOCTYPE html> \\n<html dir=\"ltr\" lang=\"de-DE\"...   \n",
       "30290  <!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n\\n<...   \n",
       "30291  <!DOCTYPE html>\\r\\n<html  lang=\"en-GB\">\\r\\n<he...   \n",
       "\n",
       "                                                    text    source country  \\\n",
       "0      DPS Software: DPS Software GmbH - Wir finden L...      xing      DE   \n",
       "1      Sales Rockstars – Kommunikationsagentur für de...      xing      DE   \n",
       "2      Paul Schmidmaier Immobilien – Immobilienmakler...      xing      DE   \n",
       "3      HDP Bauwerkzeuge - Ihr leistungsstarker Servic...      xing      DE   \n",
       "4      Avaya | Leader in Business Communication and C...  linkedin      EN   \n",
       "...                                                  ...       ...     ...   \n",
       "30287  Connex: Steuerberatung, Unternehmensberatung, ...      xing      DE   \n",
       "30288  Frettwork Network\\n\\nDE | EN | NL\\n\\n\\nFRETTWO...      xing      DE   \n",
       "30289  ERP, Infor, Comet PA\\n\\nZWF Software & Consult...      xing      DE   \n",
       "30290  IMS ENGINEERING - Homepage\\n\\nMENU\\n\\n\\nAbout ...  linkedin      EN   \n",
       "30291  Managed IT Support & Services | Browse Our Mar...  linkedin      EN   \n",
       "\n",
       "      group_representative_label  \n",
       "0                   Law Practice  \n",
       "1                   Law Practice  \n",
       "2                       Research  \n",
       "3                    Hospitality  \n",
       "4       Museums and Institutions  \n",
       "...                          ...  \n",
       "30287        Writing and Editing  \n",
       "30288   Motion Pictures and Film  \n",
       "30289               Law Practice  \n",
       "30290          Apparel & Fashion  \n",
       "30291               Law Practice  \n",
       "\n",
       "[30292 rows x 10 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "30",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-ee66c0976615>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlookup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindustry_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindustry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"group_representative_label\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlookup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_representative\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6876\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6877\u001b[0m         )\n\u001b[0;32m-> 6878\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6880\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 result = libreduction.compute_reduction(\n\u001b[0;32m--> 296\u001b[0;31m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 )\n\u001b[1;32m    298\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.compute_reduction\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.Reducer.get_result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-ee66c0976615>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlookup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindustry_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindustry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"group_representative_label\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlookup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_representative\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 30"
     ]
    }
   ],
   "source": [
    "lookup = pd.Series(train.industry_label.values, index = train.industry).to_dict() \n",
    "train[\"group_representative_label\"] = train.apply(lambda row: lookup[row.group_representative], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: 'Computer Software',\n",
       " 96: 'Information Technology and Services',\n",
       " 44: 'Real Estate',\n",
       " 133: 'Wholesale',\n",
       " 8: 'Telecommunications',\n",
       " 6: 'Internet',\n",
       " 31: 'Hospitality',\n",
       " 34: 'Food & Beverages',\n",
       " 56: 'Mining & Metals',\n",
       " 41: 'Banking',\n",
       " 53: 'Automotive',\n",
       " 135: 'Mechanical or Industrial Engineering',\n",
       " 116: 'Logistics and Supply Chain',\n",
       " 50: 'Architecture & Planning',\n",
       " 80: 'Marketing and Advertising',\n",
       " 11: 'Management Consulting',\n",
       " 15: 'Pharmaceuticals',\n",
       " 113: 'Online Media',\n",
       " 137: 'Human Resources',\n",
       " 17: 'Medical Devices',\n",
       " 48: 'Construction',\n",
       " 43: 'Financial Services',\n",
       " 124: 'Health, Wellness and Fitness',\n",
       " 27: 'Retail',\n",
       " 10: 'Legal Services',\n",
       " 42: 'Insurance',\n",
       " 144: 'Renewables & Environment',\n",
       " 55: 'Machinery',\n",
       " 112: 'Electrical/Electronic Manufacturing',\n",
       " 57: 'Oil & Energy'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30292, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some informations about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent countries:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DE    19848\n",
       "EN     8244\n",
       "NL      433\n",
       "FR      407\n",
       "ES      304\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Most frequent countries:\\n\")\n",
    "train.country.value_counts().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average/mean share of actual/plain text of HTML: 8.0%\n"
     ]
    }
   ],
   "source": [
    "text_percentage = train.apply(lambda row: len(row.text)/len(row.html), axis=1)\n",
    "\n",
    "print(f\"Average/mean share of actual/plain text of HTML: {np.round(np.mean(text_percentage), decimals=2)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_representative (21): \n",
      "\n",
      "1. 8\t2. 10\t3. 11\t4. 13\t5. 25\t6. 30\t7. 40\t8. 42\t9. 43\t10. 44\t11. 48\t12. 53\t13. 55\t14. 80\t15. 96\t16. 116\t17. 126\t18. 133\t19. 135\t20. 137\t21. 144\t"
     ]
    }
   ],
   "source": [
    "unique_classes = list(np.unique(train[CLASS_COL]))\n",
    "\n",
    "print(f\"{CLASS_COL} ({len(unique_classes)}): \\n\")\n",
    "for idx, i in enumerate(unique_classes):\n",
    "    print(str(idx+1)+\". \"+str(i), end=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsampling\n",
    "\n",
    "- Only specific language (e.g. \"DE\")\n",
    "- Only $n$ samples (e.g. 1000)\n",
    "- Stratified sampling by industry col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of classes (sampled train): 21\n",
      "Equal to original train? True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 9)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if SUBSAMPLING:\n",
    "    \n",
    "    if USED_LANG[0] != \"ALL\":\n",
    "        train = train[train.country.isin(USED_LANG)]\n",
    "    train = train.sample(n=N_SAMPLES, weights=CLASS_COL, random_state=1).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "unique_sampled_classes = len(train[CLASS_COL].unique())\n",
    "print(\"Count of classes (sampled train):\", unique_sampled_classes)\n",
    "print(\"Equal to original train?\", unique_sampled_classes == len(unique_classes))\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing (vectorizing, dimension reducing etc.)\n",
    "\n",
    "- ignore terms with a document frequency > MAX_DOCUMENT_FREQUENCY (`max_df` in TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of unique classes in train set: 21\n",
      "Count of unique languages in train set: 1\n"
     ]
    }
   ],
   "source": [
    "if TEXT_COL == \"html\":\n",
    "    POS_TAGGING = False\n",
    "train_text_plain = train[TEXT_COL].values\n",
    "\n",
    "\n",
    "train_labels = train[CLASS_COL].values\n",
    "unique_train_labels = list(np.unique(train[CLASS_COL]))\n",
    "print(\"Count of unique classes in train set:\", len(unique_train_labels))\n",
    "print(\"Count of unique languages in train set:\", len(np.unique(train[\"country\"].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No POS TAGS are removed.\n",
      "\n",
      "CPU times: user 855 µs, sys: 58 µs, total: 913 µs\n",
      "Wall time: 911 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if POS_TAGGING:\n",
    "    train_text = remove_pos(train, pos_tags=POS_TAGS)\n",
    "else:\n",
    "    train_text = train_text_plain\n",
    "    print(\"No POS TAGS are removed.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.05 s, sys: 66.2 ms, total: 8.11 s\n",
      "Wall time: 8.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=MAX_DOCUMENT_FREQUENCY,\n",
    "                             lowercase=LOWERCASE,\n",
    "                             max_features=MAX_FEATURES,\n",
    "                             stop_words=STOP_WORDS)\n",
    "\n",
    "\n",
    "vectorizer.fit(train_text)\n",
    "\n",
    "train_vector = vectorizer.transform(train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.88 s, sys: 427 ms, total: 7.31 s\n",
      "Wall time: 7.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = pd.read_csv(TEST_PATH_CSV)\n",
    "\n",
    "if SUBSAMPLING:\n",
    "    if USED_LANG[0] != \"ALL\":\n",
    "        test = test[test.country.isin(USED_LANG)]\n",
    "    test = test.sample(n=test.shape[0], weights=CLASS_COL, random_state=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "test_vector = vectorizer.transform(test[TEXT_COL].values)\n",
    "test_labels = test[CLASS_COL].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4976, 9)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes (Multinomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes CLF \n",
      "-------------------------\n",
      "0.4133 \tPrecision\n",
      "0.1782 \tRecall\n",
      "0.1466 \tF1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jan/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jan/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.int64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   1977\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m         \u001b[0mlongest_last_line_heading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'weighted avg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1979\u001b[0;31m         \u001b[0mname_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1980\u001b[0m         \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlongest_last_line_heading\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m         \u001b[0mhead_fmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{:>{width}s} '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' {:>9}'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1977\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m         \u001b[0mlongest_last_line_heading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'weighted avg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1979\u001b[0;31m         \u001b[0mname_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1980\u001b[0m         \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlongest_last_line_heading\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m         \u001b[0mhead_fmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{:>{width}s} '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' {:>9}'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.int64' has no len()"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Multinomial Naive Bayes CLF\", \"\\n-------------------------\")\n",
    "# training\n",
    "clf = MultinomialNB(alpha=1.0)\n",
    "clf.fit(train_vector, train_labels)\n",
    "\n",
    "# prediction\n",
    "train_preds = clf.predict(test_vector)\n",
    "\n",
    "# evaluation\n",
    "precision = precision_score(test_labels, train_preds, average=\"macro\")\n",
    "recall = recall_score(test_labels, train_preds, average=\"macro\")\n",
    "f1 = f1_score(test_labels, train_preds, average=\"macro\")\n",
    "\n",
    "print(np.round(precision, decimals=4), \"\\tPrecision\")\n",
    "print(np.round(recall, decimals=4), \"\\tRecall\")\n",
    "print(np.round(f1, decimals=4), \"\\tF1\")\n",
    "print()\n",
    "\n",
    "clf_report = classification_report(test_labels, train_preds, target_names = np.unique(test[CLASS_COL]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSVM CLF \n",
      "-------------------------\n",
      "0.6517 \tPrecision\n",
      "0.5683 \tRecall\n",
      "0.5486 \tF1\n",
      "\n",
      "CPU times: user 4.5 s, sys: 18.1 ms, total: 4.52 s\n",
      "Wall time: 4.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"LSVM CLF\", \"\\n-------------------------\")\n",
    "# training\n",
    "clf = LinearSVC(C = 1)\n",
    "clf.fit(train_vector, train_labels)\n",
    "\n",
    "# prediction\n",
    "train_preds = clf.predict(test_vector)\n",
    "\n",
    "# evaluation\n",
    "precision = precision_score(test_labels, train_preds, average=\"macro\")\n",
    "recall = recall_score(test_labels, train_preds, average=\"macro\")\n",
    "f1 = f1_score(test_labels, train_preds, average=\"macro\")\n",
    "print(np.round(precision, decimals=4), \"\\tPrecision\")\n",
    "print(np.round(recall, decimals=4), \"\\tRecall\")\n",
    "print(np.round(f1, decimals=4), \"\\tF1\")\n",
    "print()\n",
    "\n",
    "clf_report = classification_report(test_labels, train_preds, target_names = np.unique(test.industry_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: label und text names und so; allg. änderungen von oben hier ergänzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMALIZE_CM = True\n",
    "INDUSTRY_TRESHOLD = 250\n",
    "PLT_SCALING_FACTOR = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "filtered_train = train.groupby(\"industry_name\").filter(lambda x: len(x)>INDUSTRY_TRESHOLD)\n",
    "remaining_industries = filtered_train[\"industry_name\"].drop_duplicates().tolist()\n",
    "\n",
    "\n",
    "\n",
    "cnf_matrix = confusion_matrix(test_labels, train_preds)\n",
    "\n",
    "classes = train[\"industry_name\"].drop_duplicates().tolist()\n",
    "\n",
    "cnf_df = pd.DataFrame(cnf_matrix, index=classes, columns=classes)\n",
    "cnf_df = cnf_df[remaining_industries]\n",
    "cnf_df = cnf_df.loc[remaining_industries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10*PLT_SCALING_FACTOR, 8*PLT_SCALING_FACTOR))\n",
    "\n",
    "if NORMALIZE_CM:\n",
    "    normalized_cnf_df = cnf_df.astype('float') / cnf_df.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(normalized_cnf_df, annot=True, cmap=sns.color_palette(\"Blues\"), fmt='.2f')\n",
    "else:\n",
    "    sns.heatmap(cnf_df, annot=True, cmap=sns.color_palette(\"Blues\"), fmt='g')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
