{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Industries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODOS / IDEAS\n",
    "- Translation der Websites\n",
    "- remove pos einführen (siehe `clustering_whole_corpus`)\n",
    "    - vielleicht mit Language identifier?\n",
    "- preprocessing function einführen\n",
    "    - `\\n` weg\n",
    "    - andere unnütze Zeichen wie `|` etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDEEN\n",
    "\n",
    "- HTML Struktur verwenden, um vorher Main Content von Boilerplate Content zu entfernen:\n",
    "    - Plain Text ist sehr noisy (viel unnötiges drin)\n",
    "    - Paper / Repos:\n",
    "        - **Boilerplate Removal using a Neural Sequence Labeling Model** (2020): https://arxiv.org/pdf/2004.14294.pdf\n",
    "            - Verbesserung von **Web2Text** &rarr; basiert nicht auf teuren, handgemachten Feature Engineering\n",
    "            - <u>Hypothese</u>: \"Our hypothesis is that the **order** of text blocks in a web page **encodes important information** about their type, i.e. content or boilerplate, as the placement is determined by the authoring style\"\n",
    "        - **Web2Text: Deep Structured Boilerplate Removal** (2018): https://arxiv.org/pdf/1801.02607.pdf\n",
    "        - **Mozillas readability**: https://github.com/mozilla/readability\n",
    "        - **Webpage Classification based on Compound of Using HTML Features & URLFeatures and Features of Sibling Pages** (2010): https://www.researchgate.net/publication/220419545_Webpage_Classification_based_on_Compound_of_Using_HTML_Features_URL_Features_and_Features_of_Sibling_Pages\n",
    "        - TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "Hier werden **F1 Scores** dargestellt.\n",
    "\n",
    "| Experiment | Dummy | LSVM |\n",
    "| ---------- |:-----:| ----:|\n",
    "| Plain Text als Grundlage (kein POS Removal) | 0.01665 | 0.50609 |\n",
    "| Plain Text als Grundlage (POS Removal: VERB, ADJ, NOUN) | 0.01417 | 0.01395 |\n",
    "| HTML als Grundlage | 0.0145 | 0.46618 |\n",
    "| Clean HTML als Grundlage | 0.01554 | 0.39454 |\n",
    "| | | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn classification\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# sklearn clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# sklearn general\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "import ujson as json\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from app.utils import remove_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/\"\n",
    "\n",
    "INDUSTRY_CODES_PATH = DATA_PATH + \"linkedin-industry-codes.json\"\n",
    "TRAIN_PATH_JSON = DATA_PATH + \"train.ndjson\"\n",
    "TEST_PATH_JSON = DATA_PATH + \"test.ndjson\"\n",
    "TRAIN_PATH_CSV = DATA_PATH + \"train.csv\"\n",
    "TEST_PATH_CSV = DATA_PATH + \"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_RED = False\n",
    "MAX_DOCUMENT_FREQUENCY = 1.\n",
    "MAX_FEATURES = 1000000\n",
    "LOWERCASE = False\n",
    "\n",
    "POS_TAGGING = True\n",
    "POS_TAGS = [\"NOUN\"]\n",
    "\n",
    "SUBSAMPLING = True\n",
    "N_SAMPLES = 10000\n",
    "USED_LANG = [\"DE\"] # \"ALL\" for no removal\n",
    "\n",
    "STOP_WORDS = get_stop_words(\"de\")\n",
    "USE_HTML = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load train csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.56 s, sys: 929 ms, total: 9.49 s\n",
      "Wall time: 9.48 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>html</th>\n",
       "      <th>industry</th>\n",
       "      <th>country</th>\n",
       "      <th>industry_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home | NETZkultur GmbH\\n\\nZum Inhalt wechseln\\...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"de-DE\"&gt;\\n&lt;head&gt;\\n...</td>\n",
       "      <td>4</td>\n",
       "      <td>DE</td>\n",
       "      <td>Computer Software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nNXP Semiconductors | Automotive, Security,...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html&gt;\\n&lt;head&gt;\\n\\t&lt;title&gt;NXP ...</td>\n",
       "      <td>7</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Semiconductors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Suer Nutzfahrzeugtechnik Onlineshop\\n\\nSie wis...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"de\"&gt;\\n    &lt;head&gt;\\...</td>\n",
       "      <td>53</td>\n",
       "      <td>DE</td>\n",
       "      <td>Automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Improve cash flows and long-term profitability...</td>\n",
       "      <td>\\n&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\" prefix=\"og:...</td>\n",
       "      <td>43</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Financial Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Your specialist for plastic compounds\\n\\nMenu ...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html xmlns:og=\"http://ogp.me...</td>\n",
       "      <td>117</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Plastics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Home | NETZkultur GmbH\\n\\nZum Inhalt wechseln\\...   \n",
       "1  \\n\\nNXP Semiconductors | Automotive, Security,...   \n",
       "2  Suer Nutzfahrzeugtechnik Onlineshop\\n\\nSie wis...   \n",
       "3  Improve cash flows and long-term profitability...   \n",
       "4  Your specialist for plastic compounds\\n\\nMenu ...   \n",
       "\n",
       "                                                html  industry  country  \\\n",
       "0  <!DOCTYPE html>\\n<html lang=\"de-DE\">\\n<head>\\n...         4       DE   \n",
       "1  <!DOCTYPE html>\\n<html>\\n<head>\\n\\t<title>NXP ...         7  UNKNOWN   \n",
       "2  <!DOCTYPE html>\\n<html lang=\"de\">\\n    <head>\\...        53       DE   \n",
       "3  \\n<!DOCTYPE html>\\n<html lang=\"en\" prefix=\"og:...        43  UNKNOWN   \n",
       "4  <!DOCTYPE html>\\n<html xmlns:og=\"http://ogp.me...       117  UNKNOWN   \n",
       "\n",
       "        industry_name  \n",
       "0   Computer Software  \n",
       "1      Semiconductors  \n",
       "2          Automotive  \n",
       "3  Financial Services  \n",
       "4            Plastics  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(TRAIN_PATH_CSV)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13114, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsampling\n",
    "\n",
    "- Only specific language (e.g. \"DE\")\n",
    "- Only first $n$ samples (e.g. 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7375, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if SUBSAMPLING:\n",
    "    \n",
    "    if USED_LANG[0] != \"ALL\":\n",
    "        train = train[train.country.isin(USED_LANG)]\n",
    "    train = train.head(N_SAMPLES)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing (vectorizing, dimension reducing etc.)\n",
    "\n",
    "- ignore terms with a document frequency > MAX_DOCUMENT_FREQUENCY (`max_df` in TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of unique industry names in train set: 50\n",
      "Count of unique languages in train set: 1\n"
     ]
    }
   ],
   "source": [
    "if USE_HTML:\n",
    "    POS_TAGGING = False\n",
    "    train_text_plain = train[\"html\"].values\n",
    "else:\n",
    "    train_text_plain = train[\"text\"].values\n",
    "\n",
    "\n",
    "train_labels = train[\"industry\"].values\n",
    "unique_train_labels = list(np.unique(train[\"industry\"]))\n",
    "print(\"Count of unique industry names in train set:\", len(unique_train_labels))\n",
    "print(\"Count of unique languages in train set:\", len(np.unique(train[\"country\"].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c0a5911bb934a849f4dd45e9c350546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Country codes', max=1.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc612f9217194d828cf0818e0081beea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='DE texts', max=7375.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "CPU times: user 10min 31s, sys: 10.4 s, total: 10min 41s\n",
      "Wall time: 10min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if POS_TAGGING:\n",
    "    train_text = remove_pos(train, pos_tags=POS_TAGS)\n",
    "else:\n",
    "    train_text = train_text_plain\n",
    "    print(\"No POS TAGS are removed.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.9 s, sys: 24.4 ms, total: 2.93 s\n",
      "Wall time: 2.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=MAX_DOCUMENT_FREQUENCY,\n",
    "                             lowercase=LOWERCASE,\n",
    "                             max_features=MAX_FEATURES,\n",
    "                             stop_words=STOP_WORDS)\n",
    "\n",
    "\n",
    "\n",
    "vectorizer.fit(train_text)\n",
    "\n",
    "train_vector = vectorizer.transform(train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Dataset\n",
    "\n",
    "There is one class/industry which appears in test set but not in the training set. All instances of this class were removed from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.4 s, sys: 208 ms, total: 3.61 s\n",
      "Wall time: 3.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = pd.read_csv(TEST_PATH_CSV)\n",
    "test = test[test[\"industry\"].isin(unique_train_labels)]\n",
    "\n",
    "if SUBSAMPLING:\n",
    "    test = test[test.country.isin(USED_LANG)]\n",
    "\n",
    "\n",
    "test_vector = vectorizer.transform(test[\"text\"].values)\n",
    "test_labels = test[\"industry\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get industry names for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(INDUSTRY_CODES_PATH) as f:\n",
    "    industry_codes = json.load(f)\n",
    "    \n",
    "def get_code(code_list, identifier):\n",
    "    name = \"\"\n",
    "    for entry in code_list:\n",
    "        if entry[\"Code\"] == identifier:\n",
    "            name = entry[\"Description\"]\n",
    "            break\n",
    "    return name\n",
    "\n",
    "test_label_names = list(map(lambda x: get_code(industry_codes, x), dict(test[\"industry\"]).values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy CLF \n",
      "-------------------------\n",
      "0.02002 \tPrecision\n",
      "0.02118 \tRecall\n",
      "0.01707 \tF1\n",
      "\n",
      "CPU times: user 10.2 ms, sys: 1.87 ms, total: 12.1 ms\n",
      "Wall time: 11.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Dummy CLF\", \"\\n-------------------------\")\n",
    "clf = DummyClassifier(strategy=\"uniform\")\n",
    "clf.fit(train_vector, train_labels)\n",
    "\n",
    "train_preds = clf.predict(test_vector)\n",
    "\n",
    "precision = precision_score(test_labels, train_preds, average=\"macro\")\n",
    "recall = recall_score(test_labels, train_preds, average=\"macro\")\n",
    "f1 = f1_score(test_labels, train_preds, average=\"macro\")\n",
    "print(np.round(precision, decimals=5), \"\\tPrecision\")\n",
    "print(np.round(recall, decimals=5), \"\\tRecall\")\n",
    "print(np.round(f1, decimals=5), \"\\tF1\")\n",
    "print()\n",
    "\n",
    "clf_report = classification_report(test_labels, train_preds, target_names = np.unique(test_label_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSVM CLF \n",
      "-------------------------\n",
      "0.02765 \tPrecision\n",
      "0.02067 \tRecall\n",
      "0.01865 \tF1\n",
      "\n",
      "CPU times: user 2.97 s, sys: 11.6 ms, total: 2.98 s\n",
      "Wall time: 2.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = LinearSVC(C = 1)\n",
    "clf.fit(train_vector, train_labels)\n",
    "\n",
    "train_preds = clf.predict(test_vector)\n",
    "\n",
    "print(\"LSVM CLF\", \"\\n-------------------------\")\n",
    "precision = precision_score(test_labels, train_preds, average=\"macro\")\n",
    "recall = recall_score(test_labels, train_preds, average=\"macro\")\n",
    "f1 = f1_score(test_labels, train_preds, average=\"macro\")\n",
    "print(np.round(precision, decimals=5), \"\\tPrecision\")\n",
    "print(np.round(recall, decimals=5), \"\\tRecall\")\n",
    "print(np.round(f1, decimals=5), \"\\tF1\")\n",
    "print()\n",
    "\n",
    "clf_report = classification_report(test_labels, train_preds, target_names = np.unique(test_label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMALIZE_CM = True\n",
    "INDUSTRY_TRESHOLD = 250\n",
    "PLT_SCALING_FACTOR = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "filtered_train = train.groupby(\"industry_name\").filter(lambda x: len(x)>INDUSTRY_TRESHOLD)\n",
    "remaining_industries = filtered_train[\"industry_name\"].drop_duplicates().tolist()\n",
    "\n",
    "\n",
    "\n",
    "cnf_matrix = confusion_matrix(test_labels, train_preds)\n",
    "\n",
    "classes = train[\"industry_name\"].drop_duplicates().tolist()\n",
    "\n",
    "cnf_df = pd.DataFrame(cnf_matrix, index=classes, columns=classes)\n",
    "cnf_df = cnf_df[remaining_industries]\n",
    "cnf_df = cnf_df.loc[remaining_industries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10*PLT_SCALING_FACTOR, 8*PLT_SCALING_FACTOR))\n",
    "\n",
    "if NORMALIZE_CM:\n",
    "    normalized_cnf_df = cnf_df.astype('float') / cnf_df.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(normalized_cnf_df, annot=True, cmap=sns.color_palette(\"Blues\"), fmt='.2f')\n",
    "else:\n",
    "    sns.heatmap(cnf_df, annot=True, cmap=sns.color_palette(\"Blues\"), fmt='g')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
