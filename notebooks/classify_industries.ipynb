{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Industries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDEEN\n",
    "\n",
    "\n",
    "### HTML Klassifizierung\n",
    "\n",
    "\n",
    "- Text zusammenfassen und dann klassifizieren? Dafür auch HTML-Tags verwenden?\n",
    "- ~~HTML Struktur verwenden, um vorher **Boilerplate Content** von Main Content zu entfernen:~~\n",
    "    - ~~Plain Text ist sehr noisy (viel unnötiges drin)~~\n",
    "    - ICH: gemacht mit CLEAN HTML, aber ohne explizites Boilerplate Content Removal\n",
    "- Bestimmten Wörtern/Tags höhere Gewichtungen geben\n",
    "    - Anchor Text (= klickbarer Text in einem Hyperlink)\n",
    "        - alleine zu wenig Inhalt (QI, S. 12)\n",
    "        - umliegende Wörter interessant! (QI, S. 12)\n",
    "        - auch für Nachbar-Seiten-Ansatz\n",
    "    - Title, Headers (QI, S. 12)\n",
    "        - auch für Nachbar-Seiten-Ansatz\n",
    "    - Keywords für Branchen\n",
    "        ```python3  \n",
    "        Class_1_keywords = ['Office', 'School', 'phone', 'Technology', 'Electronics', 'Cell', 'Business', 'Education', 'Classroom']\n",
    "        \n",
    "        Class_2_keywords = ['Restaurant', 'Hospitality', 'Tub', 'Drain', 'Pool', 'Filtration', 'Floor', 'Restroom', 'Consumer', 'Care', 'Bags', 'Disposables']\n",
    "        \n",
    "        Class_3_keywords = ['Pull', 'Lifts', 'Pneumatic', 'Emergency', 'Finishing', 'Hydraulic', 'Lockout', 'Towers', 'Drywall', 'Tools', 'Packaging', 'Measure', 'Tag ']\n",
    "        ```\n",
    "- NER mit **Tags** als weitere Tokens\n",
    "- Features von \"Nachbarseiten\" verwenden\n",
    "    - Hilfreich, da mehr Infos als \"nur\" Startseite\n",
    "    - Fragen: \n",
    "        - Was sind Nachbarseiten, wie definieren?\n",
    "            - Webgraph Webseiten?\n",
    "            - Weitere Seiten des Unternehmens?\n",
    "        - Wie viele Nachbarseiten?\n",
    "        - Wieviel von den Nachbarseiten verwenden?\n",
    "            - Ganze Seite?\n",
    "            - text, title, heading, Metadaten?\n",
    "    \n",
    "- *Weiteres*:\n",
    "    - Flat classification oder Hierarchical classification?\n",
    "        - Flat: parallele Klassen\n",
    "        - Hierarchical: hierarchische Klassen, bauen aufeinander auf\n",
    "    - Nur nach bestimmten Keywords filtern? (das geht jedoch mehr Richtung PLAIN-Textclassification)\n",
    "    - \"implicit links\": Seiten, die beide bei Suche von **Suchmaschine** erschienen sind und auf die beide der User geklickt hat (QI, S. 12) &rarr; nicht wirklich realisierbar\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "- Evaluation metric: **F1 Scores**\n",
    "- TF-IDF Vectorizer\n",
    "    - kein lowercase\n",
    "    - stop words werden entfernt\n",
    "    - keine max features\n",
    "- Top $n$ classes = most frequent classes\n",
    "- CLEAN HTML auch für Test Set (ansonsten unglaublich schlechte Accuracy und etwas sinnlos)\n",
    "\n",
    "\n",
    "#### Label: `group_representatives`\n",
    "\n",
    "| Experiment | SGD F1 (Precision) | LSVM F1 (Precision) |\n",
    "| ---------- |:-----:| ----:|\n",
    "| HTML (10000 features) | **0.5292** (0.5962) | **0.5493** (0.6371) |\n",
    "| HTML (kept stop words) (10000 features) | **0.5268** (0.5845) | **0.5473** (0.6439) |\n",
    "| HTML (10000 features) ((1, 3) ngrams) | **0.4035** (0.463) | **0.4188** (0.5345) |\n",
    "| HTML (10000 features) ((2, 2) ngrams) | **0.2442** (0.2787) | **0.252** (0.3146) |\n",
    "| ---------- |-----| ----|\n",
    "| *ALL LANGS* HTML (kept stop words) (10000 features) | **0.5781** (0.6464) | **0.6406** (0.7024) |\n",
    "| ---------- |-----| ----|\n",
    "| Plain Text (kept stop words) (10000 features) (10000 rows) | **0.5841** (0.6301) | **0.5778** (0.6257) |\n",
    "| Plain Text + Meta (kept stop words) (10000 features) (10000 rows) | **0.5832** (0.6197) | **0.5826** (0.6279) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn classification\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# sklearn general\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.metrics import (confusion_matrix, \n",
    "                             classification_report, \n",
    "                             f1_score, \n",
    "                             precision_score,\n",
    "                             recall_score)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "import ujson as json\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from app.utils import (clean_boilerplate, \n",
    "                       clean_website, \n",
    "                       detect_XML, \n",
    "                       extract_meta_informations,\n",
    "                       remove_tags, \n",
    "                       tokenizing_html, \n",
    "                       trim_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_PATH = \"../data/\"\n",
    "LANG = \"\"\n",
    "ROWS = \"_10000\"\n",
    "\n",
    "INDUSTRIES_PATH_CSV = DATA_DIR_PATH + \"industries.csv\"\n",
    "TRAIN_PATH_CSV = DATA_DIR_PATH + \"train\" + LANG + ROWS + \".csv\"\n",
    "TEST_PATH_CSV = DATA_DIR_PATH + \"test\" + LANG + ROWS +\".csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.5 s, sys: 383 ms, total: 2.88 s\n",
      "Wall time: 2.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(TRAIN_PATH_CSV)\n",
    "train = train.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>industry</th>\n",
       "      <th>industry_label</th>\n",
       "      <th>group</th>\n",
       "      <th>group_representative</th>\n",
       "      <th>html</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>country</th>\n",
       "      <th>group_representative_label</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.autarctech.de</td>\n",
       "      <td>144</td>\n",
       "      <td>Renewables &amp; Environment</td>\n",
       "      <td>gov, man, org</td>\n",
       "      <td>144</td>\n",
       "      <td>&lt;html&gt;    &lt;head&gt;                              ...</td>\n",
       "      <td>Home\\n\\nMenü\\n\\n\\nShop\\nHome\\nProdukte\\nOur St...</td>\n",
       "      <td>xing</td>\n",
       "      <td>DE</td>\n",
       "      <td>Renewables &amp; Environment</td>\n",
       "      <td>Effizenz bei der Stromspeicherung in Batterien...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        url  industry            industry_label  \\\n",
       "0  http://www.autarctech.de       144  Renewables & Environment   \n",
       "\n",
       "           group  group_representative  \\\n",
       "0  gov, man, org                   144   \n",
       "\n",
       "                                                html  \\\n",
       "0  <html>    <head>                              ...   \n",
       "\n",
       "                                                text source country  \\\n",
       "0  Home\\n\\nMenü\\n\\n\\nShop\\nHome\\nProdukte\\nOur St...   xing      DE   \n",
       "\n",
       "  group_representative_label  \\\n",
       "0   Renewables & Environment   \n",
       "\n",
       "                                                meta  \n",
       "0  Effizenz bei der Stromspeicherung in Batterien...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 11)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"text\" or \"html\"\n",
    "TEXT_COL = \"text\"\n",
    "\n",
    "# \"group_representative\", \"group_representative_label\", \"industry\", \"industry_label\" or \"group\"\n",
    "CLASS_COL = \"group_representative\"\n",
    "CLASS_NAMES = \"group_representative_label\"\n",
    "\n",
    "MAX_DOCUMENT_FREQUENCY = 1.\n",
    "MAX_FEATURES = 10000\n",
    "NGRAM_RANGE = (1,1)\n",
    "LOWERCASE = False\n",
    "#STOP_WORDS = get_stop_words(\"de\")\n",
    "STOP_WORDS = None\n",
    "\n",
    "TAG_LIST = ['a', 'b', 'em', 'h1', 'h2', 'h3', 'i', 'li', 'p', 'strong', 'title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Meta-Tag information to plain text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"text\"] = train[\"text\"] + train[\"meta\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trim HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/industry/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4136\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4137\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4138\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n",
      "\u001b[0;32m~/projects/industryhtml/app/utils.py\u001b[0m in \u001b[0;36mtrim_html\u001b[0;34m(html_string, tag_list, tagless_output_string, return_tree)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;34m\"\"\" Trim a html string file by removing all tags which are not inside the tag list.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0munique_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0munique_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0melement\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munique_tags\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtag_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/industry/lib/python3.9/site-packages/lxml/html/__init__.py\u001b[0m in \u001b[0;36mfromstring\u001b[0;34m(html, base_url, parser, **kw)\u001b[0m\n\u001b[1;32m    873\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0mis_full_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_looks_like_full_html_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocument_fromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_full_html\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/industry/lib/python3.9/site-packages/lxml/html/__init__.py\u001b[0m in \u001b[0;36mdocument_fromstring\u001b[0;34m(html, parser, ensure_head_body, **kw)\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtml_parser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         raise etree.ParserError(\n",
      "\u001b[0;32msrc/lxml/etree.pyx\u001b[0m in \u001b[0;36mlxml.etree.fromstring\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._parseMemoryDocument\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train[\"html\"] = train[\"html\"].apply(lambda x: trim_html(x, tag_list = TAG_LIST, tagless_output_string=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.46 s, sys: 63.5 ms, total: 8.52 s\n",
      "Wall time: 8.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_text = train[TEXT_COL]\n",
    "train_labels = train[CLASS_COL].values\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=MAX_DOCUMENT_FREQUENCY,\n",
    "                             lowercase=LOWERCASE,\n",
    "                             max_features=MAX_FEATURES,\n",
    "                             ngram_range=NGRAM_RANGE,\n",
    "                             stop_words=STOP_WORDS,\n",
    "                            tokenizer=tokenizing_html)\n",
    "transformer = TfidfTransformer()\n",
    "\n",
    "vector = vectorizer.fit_transform(train_text)\n",
    "train_vector = transformer.fit_transform(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.18 s, sys: 28.6 ms, total: 2.21 s\n",
      "Wall time: 2.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = pd.read_csv(TEST_PATH_CSV)\n",
    "    \n",
    "test_vector = vectorizer.transform(test[TEXT_COL].values)\n",
    "test_vector = transformer.transform(test_vector)\n",
    "test_labels = test[CLASS_COL].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD CLF \n",
      "-------------------------\n",
      "0.6301 \tPrecision\n",
      "0.5634 \tRecall\n",
      "0.5841 \tF1\n",
      "\n",
      "CPU times: user 1.09 s, sys: 0 ns, total: 1.09 s\n",
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"SGD CLF\", \"\\n-------------------------\")\n",
    "# training\n",
    "clf = SGDClassifier()\n",
    "clf.fit(train_vector, train_labels)\n",
    "\n",
    "# prediction\n",
    "train_preds = clf.predict(test_vector)\n",
    "\n",
    "# evaluation\n",
    "precision = precision_score(test_labels, train_preds, average=\"macro\", zero_division=0)\n",
    "recall = recall_score(test_labels, train_preds, average=\"macro\", zero_division=0)\n",
    "f1 = f1_score(test_labels, train_preds, average=\"macro\", zero_division=0)\n",
    "clf1_f1 = np.round(f1, decimals=4)\n",
    "clf1_precision = np.round(precision, decimals=4)\n",
    "\n",
    "print(np.round(precision, decimals=4), \"\\tPrecision\")\n",
    "print(np.round(recall, decimals=4), \"\\tRecall\")\n",
    "print(np.round(f1, decimals=4), \"\\tF1\")\n",
    "print()\n",
    "\n",
    "clf1_report = classification_report(test_labels, \n",
    "                                   train_preds, \n",
    "                                   target_names = np.unique(test[CLASS_NAMES]), \n",
    "                                   zero_division = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSVM CLF \n",
      "-------------------------\n",
      "0.6257 \tPrecision\n",
      "0.5523 \tRecall\n",
      "0.5778 \tF1\n",
      "\n",
      "CPU times: user 2.44 s, sys: 8.03 ms, total: 2.45 s\n",
      "Wall time: 2.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"LSVM CLF\", \"\\n-------------------------\")\n",
    "# training\n",
    "clf = LinearSVC()\n",
    "clf.fit(train_vector, train_labels)\n",
    "\n",
    "# prediction\n",
    "train_preds = clf.predict(test_vector)\n",
    "\n",
    "# evaluation\n",
    "precision = precision_score(test_labels, train_preds, average=\"macro\", zero_division=0)\n",
    "recall = recall_score(test_labels, train_preds, average=\"macro\", zero_division=0)\n",
    "f1 = f1_score(test_labels, train_preds, average=\"macro\", zero_division=0)\n",
    "clf2_f1 = np.round(f1, decimals=4)\n",
    "clf2_precision = np.round(precision, decimals=4)\n",
    "\n",
    "print(np.round(precision, decimals=4), \"\\tPrecision\")\n",
    "print(np.round(recall, decimals=4), \"\\tRecall\")\n",
    "print(np.round(f1, decimals=4), \"\\tF1\")\n",
    "print()\n",
    "\n",
    "clf2_report = classification_report(test_labels, \n",
    "                                   train_preds, \n",
    "                                   target_names = np.unique(test[CLASS_NAMES]),\n",
    "                                   zero_division = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_representative\n",
      "\n",
      "| Plain Text (kept stop words) (10000 features) (10000 rows) | **0.5841** (0.6301) | **0.5778** (0.6257) |\n"
     ]
    }
   ],
   "source": [
    "result = \"| \"\n",
    "\n",
    "if TEXT_COL == \"text\":\n",
    "    result += \"Plain Text\"\n",
    "else:\n",
    "    result += \"HTML\"\n",
    "    \n",
    "if STOP_WORDS is None:\n",
    "    result += \" (kept stop words)\"\n",
    "    \n",
    "if MAX_FEATURES is None:\n",
    "    result += \" (all features)\"\n",
    "else:\n",
    "    result += f\" ({MAX_FEATURES} features)\"\n",
    "    \n",
    "if NGRAM_RANGE != (1,1):\n",
    "    result += f\" ({NGRAM_RANGE} ngrams)\"\n",
    "    \n",
    "if ROWS:\n",
    "    result += f\" ({ROWS[1:]} rows)\"\n",
    "    \n",
    "            \n",
    "result += f\" | **{clf1_f1}** ({clf1_precision}) | **{clf2_f1}** ({clf2_precision}) |\"\n",
    "print(CLASS_COL)\n",
    "print()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: label und text names und so; allg. änderungen von oben hier ergänzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMALIZE_CM = True\n",
    "INDUSTRY_TRESHOLD = 250\n",
    "PLT_SCALING_FACTOR = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "filtered_train = train.groupby(CLASS_COL).filter(lambda x: len(x)>INDUSTRY_TRESHOLD)\n",
    "remaining_industries = filtered_train[CLASS_NAMES].drop_duplicates().tolist()\n",
    "\n",
    "\n",
    "cnf_matrix = confusion_matrix(test_labels, train_preds)\n",
    "\n",
    "classes = train[CLASS_COL].drop_duplicates().tolist()\n",
    "\n",
    "cnf_df = pd.DataFrame(cnf_matrix, index=classes, columns=classes)\n",
    "cnf_df = cnf_df[remaining_industries]\n",
    "cnf_df = cnf_df.loc[remaining_industries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10*PLT_SCALING_FACTOR, 8*PLT_SCALING_FACTOR))\n",
    "\n",
    "if NORMALIZE_CM:\n",
    "    normalized_cnf_df = cnf_df.astype('float') / cnf_df.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(normalized_cnf_df, annot=True, cmap=sns.color_palette(\"Blues\"), fmt='.2f')\n",
    "else:\n",
    "    sns.heatmap(cnf_df, annot=True, cmap=sns.color_palette(\"Blues\"), fmt='g')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
